{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G233yNiDOnLp"
   },
   "source": [
    "# First things first\n",
    "* Click **File -> Save a copy in Drive** and click **Open in new tab** in the pop-up window to save your progress in Google Drive.\n",
    "* Click **Runtime -> Change runtime type** and select **GPU** in Hardware accelerator box to enable faster GPU training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74KEu1L8OnLq"
   },
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r94_BRA-OnLr"
   },
   "source": [
    "In this assignment, you will build Variational Autoencoder, train it on the MNIST dataset, and play with its architecture and hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyLQLqBcOnLt"
   },
   "source": [
    "### Setup\n",
    "Loading auxiliary files and importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "naC94KtXOnLt"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    print(\"Downloading Colab files\")\n",
    "    ! shred -u setup_google_colab.py\n",
    "    ! wget https://raw.githubusercontent.com/hse-aml/bayesian-methods-for-ml/master/setup_google_colab.py -O setup_google_colab.py\n",
    "    import setup_google_colab\n",
    "    setup_google_colab.load_data_week5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-hJ6_wBOnLz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, InputLayer, concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from w5_grader import VAEGrader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KyZf9DsOOnL2"
   },
   "source": [
    "### Grading\n",
    "We will create a grader instance below and use it to collect your answers. Note that these outputs will be stored locally inside grader and will be uploaded to the platform only after running submit function in the last part of this assignment. If you want to make a partial submission, you can run that cell anytime you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5D7sEDBOnL3"
   },
   "outputs": [],
   "source": [
    "grader = VAEGrader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnkOQUeSOnL5"
   },
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmV9OxiIOnL7"
   },
   "source": [
    "Recall that Variational Autoencoder is a probabilistic model of data based on a continious mixture of distributions. In the lecture we covered the mixture of gaussians case, but here we will apply VAE to binary MNIST images (each pixel is either black or white). To better model binary data we will use a continuous mixture of binomial distributions: $p(x \\mid w) = \\int p(x \\mid t, w) p(t) dt$, where the prior distribution on the latent code $t$ is standard normal $p(t) = \\mathcal{N}(0, I)$, but probability that $(i, j)$-th pixel is black equals to $(i, j)$-th output of the decoder neural detwork: $p(x_{i, j} \\mid t, w) = \\text{decoder}(t, w)_{i, j}$.\n",
    "\n",
    "To train this model we would like to maximize marginal log-likelihood of our dataset $\\max_w \\log p(X \\mid w)$, but it's very hard to do computationally, so instead we maximize the Variational Lower Bound w.r.t. both the original parameters $w$ and variational distribution $q$ which we define as encoder neural network with parameters $\\phi$ which takes input image $x$ and outputs parameters of the gaussian distribution $q(t \\mid x, \\phi)$: $\\log p(X \\mid w) \\geq \\mathcal{L}(w, \\phi) \\rightarrow \\max_{w, \\phi}$.\n",
    "\n",
    "So overall our model looks as follows: encoder takes an image $x$, produces a distribution over latent codes $q(t \\mid x)$ which should approximate the posterior distribution $p(t \\mid x)$ (at least after training), samples a point from this distribution $\\widehat{t} \\sim q(t \\mid x, \\phi)$, and finally feeds it into a decoder that outputs a distribution over images.\n",
    "\n",
    "![](https://github.com/hse-aml/bayesian-methods-for-ml/blob/master/week5/VAE.png?raw=1)\n",
    "\n",
    "In the lecture, we also discussed that variational lower bound has an expected value inside which we are going to approximate with sampling. But it is not trivial since we need to differentiate through this approximation. However, we learned about _reparametrization trick_ which suggests instead of sampling from distribution $\\widehat{t} \\sim q(t \\mid x, \\phi)$ sample from a distribution which doesn't depend on any parameters, e.g. standard normal, and then deterministically transform this sample to the desired one: $\\varepsilon \\sim \\mathcal{N}(0, I); ~~\\widehat{t} = m(x, \\phi) + \\varepsilon \\sigma(x, \\phi)$. This way we don't have to worry about our stochastic gradient being biased and can straightforwardly differentiate our loss w.r.t. all the parameters while treating the current sample $\\varepsilon$ as constant.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVszOw7ROnL8"
   },
   "source": [
    "### Negative Variational Lower Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRMMKLiGOnL9"
   },
   "source": [
    "**Task 1** Derive and implement Variational Lower Bound for the continuous mixture of Binomial distributions.\n",
    "\n",
    "**Note** that in lectures we discussed maximizing the VLB (which is typically a negative number), but in this assignment, for convenience, we will **minimize** the **negated** version of VLB (which will be a positive number) instead of maximizing the usual VLB. In what follows we always talk about _negated_ VLB, even when we use the term VLB for short.\n",
    "\n",
    "**Also note** that to pass the test, your code should work with any mini-batch size.\n",
    "\n",
    "To do that, we need a stochastic estimate of VLB: \n",
    "$$\\text{VLB} = \\sum_{i=1}^N \\text{VLB}_i \\approx \\frac{N}{M}\\sum_{i_s}^M \\text{VLB}_{i_s}$$\n",
    "where $N$ is the dataset size, $\\text{VLB}_i$ is the term of VLB corresponding to the $i$-th object, and $M$ is the mini-batch size. But instead of this stochastic estimate of the full VLB we will use an estimate of the negated VLB normalized by the dataset size, i.e. in the function below you need to return average across the mini-batch $-\\frac{1}{M}\\sum_{i_s}^M \\text{VLB}_{i_s}$. People usually optimize this normalized version of VLB since it doesn't depend on the dataset set - you can write VLB function once and use it for different datasets - the dataset size won't affect the learning rate too much. The correct value for this normalized negated VLB should be around $100 - 170$ in the example below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Analysis:\n",
    "$$VLB_i(w,q) = E_(q_i)[log(p(x_i|t_i,w))] - KL(q_i || p_i) $$\n",
    "$$         \\approx log(p(x_i | \\hat{t_i},w)) - KL(q_i||p_i)$$\n",
    "for part $log(p(x_i | \\hat{t_i},w)))$\n",
    "$$ log(p(x_i | \\hat{t_i},w))) = log(\\prod_{j,x_{i,j}\\text{ ,is black}} \\mu_\\hat{t_i} \\prod_{j,x_{i,j}\\text{ ,is white}} 1 - \\mu_\\hat{t_i} ) $$\n",
    "但是我感觉不对而且会出现-inf的问题。试试用讲义里边的公式好了... $||x - \\mu||^2$ 不并不应该用讲义里的，而是的确应该使用自己推导的这个，binary cross entropy. 但是自己的公式有bug，试试用keras的\n",
    "\n",
    "\n",
    "for part of KL\n",
    "$$  \\text{KL} =\\frac{1}{2}* (-log(\\sigma_{q_i}^2) + \\sigma_{q_i}^2 + \\mu_{q_i}^2 -1)   $$\n",
    "$$  \\text{KL} =-log\\sigma_{q_i} + \\frac{1}{2}(\\sigma_{q_i}^2 + \\mu_{q_i}^2 -1)   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwynsmjaOnL-"
   },
   "outputs": [],
   "source": [
    "\n",
    "def myReconstrcutionLoss(x, x_decoded_mean, t_mean, t_log_var):\n",
    "    log_x_decoded_mean_black = tf.math.log(x_decoded_mean + 0.000001)\n",
    "    log_x_decoded_mean_white = tf.math.log(1 - x_decoded_mean + 0.000001)\n",
    "    log_px_black = tf.reduce_sum((x) * log_x_decoded_mean_black)\n",
    "    log_px_white = tf.reduce_sum((x - 1)  * log_x_decoded_mean_white *-1)\n",
    "    log_px = log_px_black + log_px_white\n",
    "#     return log_px\n",
    "#     return tf.reduce_sum(keras.losses.binary_crossentropy(x, x_decoded_mean))\n",
    "    \n",
    "\n",
    "\n",
    "def myKLLoss(x, x_decoded_mean, t_mean, t_log_var):\n",
    "    t_var = tf.math.exp(t_log_var)\n",
    "    KL = tf.reduce_sum(-0.5 * t_log_var + 0.5*(t_var + t_mean**2 -1)) * -1\n",
    "    return KL\n",
    "\n",
    "def vlb_binomial(x, x_decoded_mean, t_mean, t_log_var):\n",
    "    \"\"\"Returns the value of negative Variational Lower Bound\n",
    "    \n",
    "    The inputs are tf.Tensor\n",
    "        x: (batch_size x number_of_pixels) matrix with one image per row with zeros and ones\n",
    "        x_decoded_mean: (batch_size x number_of_pixels) mean of the distribution p(x | t), real numbers from 0 to 1\n",
    "        t_mean: (batch_size x latent_dim) mean vector of the (normal) distribution q(t | x)\n",
    "        t_log_var: (batch_size x latent_dim) logarithm of the variance vector of the (normal) distribution q(t | x)\n",
    "    \n",
    "    Returns:\n",
    "        A tf.Tensor with one element (averaged across the batch), VLB\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    # for part log(p(xi | hat(ti),w)) :\n",
    "    # assume black is 1 and white is 0\n",
    "    reconsturction_loss = myReconstrcutionLoss(x, x_decoded_mean, t_mean, t_log_var)\n",
    "    KL_loss = myKLLoss(x, x_decoded_mean, t_mean, t_log_var)\n",
    "    negative_VLB = (-reconsturction_loss - KL_loss) / x.shape[0]\n",
    "    \n",
    "    return negative_VLB\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpZjbDz0OnMA"
   },
   "outputs": [],
   "source": [
    "# # Start tf session so we can run code.\n",
    "# sess = tf.InteractiveSession()\n",
    "# # sess = tf.compat.v1.keras.backend.get_session()\n",
    "# # Connect keras to the created session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpZjbDz0OnMA"
   },
   "outputs": [],
   "source": [
    "# # K.set_session(sess)\n",
    "# tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.59494"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.load('test_data.npz')\n",
    "loss = vlb_binomial(test_data['x'], test_data['x_decoded_mean'], test_data['t_mean'], test_data['t_log_var'])\n",
    "loss\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJoWFRnDOnMF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-512616.8, shape=(), dtype=float32)\n",
      "tf.Tensor(19.494862, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "log_x_decoded_mean_black = tf.math.log(test_data['x_decoded_mean'] + 0.00001)\n",
    "log_x_decoded_mean_white = tf.math.log(1 - test_data['x_decoded_mean'] + 0.00001)\n",
    "log_px_black = tf.reduce_sum((1-test_data['x']) * log_x_decoded_mean_black)\n",
    "log_px_white = tf.reduce_sum(test_data['x']  * log_x_decoded_mean_white)\n",
    "log_px1 = log_px_black + log_px_white\n",
    "bce = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "log_px2 = bce(test_data['x'], test_data['x_decoded_mean'])\n",
    "print(log_px1)\n",
    "print(tf.reduce_sum(log_px2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-512616.8>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(log_px1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=19.494862>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(log_px2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task 1 (vlb) is: 157.59497\n"
     ]
    }
   ],
   "source": [
    "grader.submit_part('S66Mi', str(loss.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIajOY9bOnMK"
   },
   "source": [
    "## Encoder / decoder definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agpMFTzKOnML"
   },
   "source": [
    "**Task 2** Read the code below that defines encoder and decoder networks and implement sampling with reparametrization trick in the provided space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uY_dcGHmOnML"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "original_dim = 784 # Number of pixels in MNIST images.\n",
    "latent_dim = 3 # d, dimensionality of the latent code t.\n",
    "intermediate_dim = 256 # Size of the hidden layer.\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uY_dcGHmOnML"
   },
   "outputs": [],
   "source": [
    "# x = keras.Input(shape=(784,))\n",
    "# x = Input(batch_shape=(batch_size, original_dim))\n",
    "# def create_encoder(input_dim):\n",
    "#     # Encoder network.\n",
    "#     # We instantiate these layers separately so as to reuse them later\n",
    "#     encoder = Sequential(name='encoder')\n",
    "#     encoder.add(InputLayer([input_dim]))\n",
    "#     encoder.add(Dense(intermediate_dim, activation='relu'))\n",
    "#     encoder.add(Dense(2 * latent_dim))\n",
    "#     return encoder\n",
    "# encoder = create_encoder(original_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uY_dcGHmOnML"
   },
   "outputs": [],
   "source": [
    "get_t_mean = Lambda(lambda h: h[:, :latent_dim])\n",
    "get_t_log_var = Lambda(lambda h: h[:, latent_dim:])\n",
    "h = encoder(x)\n",
    "t_mean = get_t_mean(h)\n",
    "t_log_var = get_t_log_var(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 3])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uY_dcGHmOnML"
   },
   "outputs": [],
   "source": [
    "# Sampling from the distribution \n",
    "#     q(t | x) = N(t_mean, exp(t_log_var))\n",
    "# with reparametrization trick.\n",
    "\n",
    "def sampling(args):\n",
    "    \"\"\"Returns sample from a distribution N(args[0], diag(args[1]))\n",
    "    \n",
    "    The sample should be computed with reparametrization trick.\n",
    "    \n",
    "    The inputs are tf.Tensor\n",
    "        args[0]: (batch_size x latent_dim) mean of the desired distribution\n",
    "        args[1]: (batch_size x latent_dim) logarithm of the variance vector of the desired distribution\n",
    "    \n",
    "    Returns:\n",
    "        A tf.Tensor of size (batch_size x latent_dim), the samples.\n",
    "    \"\"\"\n",
    "    t_mean, t_log_var = args\n",
    "    # YOUR CODE HERE\n",
    "    sample_std = tf.math.exp(t_log_var / 2.0)\n",
    "    sample_shape = t_mean.shape\n",
    "    sampled_normal = tf.random.normal(sample_shape)\n",
    "    return t_mean + sample_std * sampled_normal\n",
    "\n",
    "\n",
    "t = Lambda(sampling)([t_mean, t_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uY_dcGHmOnML"
   },
   "outputs": [],
   "source": [
    "# def create_decoder(input_dim):\n",
    "#     # Decoder network\n",
    "#     # We instantiate these layers separately so as to reuse them later\n",
    "#     decoder = Sequential(name='decoder')\n",
    "#     decoder.add(InputLayer([input_dim]))\n",
    "#     decoder.add(Dense(intermediate_dim, activation='relu'))\n",
    "#     decoder.add(Dense(original_dim, activation='sigmoid'))\n",
    "#     return decoder\n",
    "# decoder = create_decoder(latent_dim)\n",
    "# x_decoded_mean = decoder(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self,args):\n",
    "        \"\"\"Returns sample from a distribution N(args[0], diag(args[1]))\n",
    "    \n",
    "        The sample should be computed with reparametrization trick.\n",
    "\n",
    "        The inputs are tf.Tensor\n",
    "            args[0]: (batch_size x latent_dim) mean of the desired distribution\n",
    "            args[1]: (batch_size x latent_dim) logarithm of the variance vector of the desired distribution\n",
    "\n",
    "        Returns:\n",
    "            A tf.Tensor of size (batch_size x latent_dim), the samples.\n",
    "        \"\"\"\n",
    "        t_mean, t_log_var = args\n",
    "        # YOUR CODE HERE\n",
    "        sample_std = tf.math.exp(t_log_var / 2.0)\n",
    "        sample_shape = tf.shape(t_mean)\n",
    "        sampled_normal = tf.random.normal(sample_shape)\n",
    "        return t_mean + sample_std * sampled_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXhY1G7POnMN"
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "test_data = np.load('test_data.npz')\n",
    "my_t_mean = tf.tile(test_data['t_mean'][:1, :], [10000, 1])\n",
    "my_t_log_var = tf.tile(test_data['t_log_var'][:1, :], [10000, 1])\n",
    "samples = Sampling()([my_t_mean, my_t_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXhY1G7POnMN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task 2.1 (samples mean) is: -0.122772776\n",
      "Current answer for task 2.2 (samples var) is: 0.03795461\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(samples, axis=0)[1]\n",
    "var = np.var(samples, axis=0)[1]\n",
    "grader.submit_part('dXfpy', str(grader.ravel_output(mean)))\n",
    "grader.submit_part('U1gJG', str(grader.ravel_output(var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Encoder and Decoder\n",
    "# ref: ()https://keras.io/examples/generative/vae/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_60 (InputLayer)           [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 64)           50240       input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "t_mean (Dense)                  (None, 3)            195         dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "t_log_var (Dense)               (None, 3)            195         dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sampling_9 (Sampling)           (None, 3)            0           t_mean[0][0]                     \n",
      "                                                                 t_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 50,630\n",
      "Trainable params: 50,630\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# setting\n",
    "batch_size = 100\n",
    "original_dim = 784 # Number of pixels in MNIST images.\n",
    "latent_dim = 3 # d, dimensionality of the latent code t.\n",
    "intermediate_dim = 64 # Size of the hidden layer.\n",
    "epochs = 3\n",
    "\n",
    "# create encoder\n",
    "encoder_inputs = keras.Input(shape=(784,))\n",
    "x = Dense(intermediate_dim,activation=\"relu\")(encoder_inputs)\n",
    "t_mean = Dense(latent_dim,name=\"t_mean\")(x)\n",
    "t_log_var = Dense(latent_dim,name = \"t_log_var\")(x)\n",
    "t = Sampling()([t_mean,t_log_var])\n",
    "encoder = keras.Model(inputs=encoder_inputs, outputs = [t_mean,t_log_var,t],name=\"encoder\")\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_61 (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 784)               50960     \n",
      "=================================================================\n",
      "Total params: 51,216\n",
      "Trainable params: 51,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create decoder\n",
    "decoder_inputs = Input(shape=(latent_dim,))\n",
    "x = Dense(intermediate_dim,activation=\"relu\")(decoder_inputs)\n",
    "d_outputs = Dense(original_dim,activation=\"sigmoid\")(x)\n",
    "decoder = Model(decoder_inputs,d_outputs,name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVAE(Model):\n",
    "    def __init__(self,encoder,decoder,**kwargs):\n",
    "        super(MyVAE,self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.kl_loss = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.reconstruction_loss = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss,self.reconstruction_loss,self.kl_loss]\n",
    "    \n",
    "    def train_step(self,data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            t_mean,t_log_var,t = self.encoder(data)\n",
    "            reconstruction = self.decoder(t)\n",
    "            reconstruction_loss = myReconstrcutionLoss(data,reconstruction,t_mean,t_log_var)\n",
    "            kl_loss = -0.5 * (1 + t_log_var - tf.square(t_mean) - tf.exp(t_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = kl_loss + reconstruction_loss\n",
    "        grad = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grad,self.trainable_weights))\n",
    "        self.total_loss.update_state(total_loss)\n",
    "        self.reconstruction_loss.update_state(reconstruction_loss)\n",
    "        self.kl_loss.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss.result(),\n",
    "            \"kl_loss\": self.kl_loss.result(),\n",
    "        }\n",
    "myVae = MyVAE(encoder,decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nktDqnapOnMS"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bcs69AvMOnMT"
   },
   "source": [
    "**Task 3** Run the cells below to train the model with the default settings. Modify the parameters to get better results. Especially pay attention to the encoder/decoder architectures (e.g. using more layers, maybe making them convolutional), learning rate, and the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZC2LPovUOnMU"
   },
   "outputs": [],
   "source": [
    "\n",
    "# vae = Model(x, x_decoded_mean)\n",
    "# # Keras will provide input (x) and output (x_decoded_mean) to the function that\n",
    "# # should construct loss, but since our function also depends on other\n",
    "# # things (e.g. t_means), it is easier to build the loss in advance and pass\n",
    "# # a function that always returns it.\n",
    "# # vae.compile(optimizer=keras.optimizers.RMSprop(lr=0.001), loss=keras.losses.mse)\n",
    "# vae.compile(optimizer=keras.optimizers.RMSprop(lr=0.001), loss=wrapper_loss)\n",
    "# # vae.compile(optimizer=keras.optimizers.RMSprop(lr=0.001), loss=lambda x,y:vlb_binomial)\n",
    "# vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "myVae.compile(optimizer=keras.optimizers.RMSprop(lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SVJQG9l4OnMY"
   },
   "source": [
    "#### Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AS79kH0VOnMZ"
   },
   "outputs": [],
   "source": [
    "# train the VAE on MNIST digits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# One hot encoding.\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EnWfL2xrOnMb"
   },
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J_-zXvnpOnMc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-392-bc82617beefc>:18 train_step\n        reconstruction_loss = myReconstrcutionLoss(data,reconstruction,t_mean,t_log_var)\n    <ipython-input-391-87c703828e36>:6 myReconstrcutionLoss\n        log_px_white = tf.reduce_sum((x - 1)  * log_x_decoded_mean_white *-1)\n\n    TypeError: unsupported operand type(s) for -: 'tuple' and 'int'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-395-c7fab8f866f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                validation_data=(x_test, x_test))\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 697\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-392-bc82617beefc>:18 train_step\n        reconstruction_loss = myReconstrcutionLoss(data,reconstruction,t_mean,t_log_var)\n    <ipython-input-391-87c703828e36>:6 myReconstrcutionLoss\n        log_px_white = tf.reduce_sum((x - 1)  * log_x_decoded_mean_white *-1)\n\n    TypeError: unsupported operand type(s) for -: 'tuple' and 'int'\n"
     ]
    }
   ],
   "source": [
    "hist = myVae.fit(x=x_train, y=x_train,\n",
    "               shuffle=True,\n",
    "               epochs=epochs,\n",
    "               batch_size=batch_size,\n",
    "               validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FdjnEbpkOnMf"
   },
   "source": [
    "### Visualize reconstructions for train and validation data\n",
    "In the picture below you can see the reconstruction ability of your network on training and validation data. In each of the two images, the left column is MNIST images and the right column is the corresponding image after passing through autoencoder (or more precisely the mean of the binomial distribution over the output images).\n",
    "\n",
    "Note that getting the best possible reconstruction is not the point of VAE, the KL term of the objective specifically hurts the reconstruction performance. But the reconstruction should be anyway reasonable and they provide a visual debugging tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDAjZV_kOnMf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "for fid_idx, (data, title) in enumerate(\n",
    "            zip([x_train, x_test], ['Train', 'Validation'])):\n",
    "    n = 10  # figure with 10 x 2 digits\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * 2))\n",
    "#     decoded = sess.run(x_decoded_mean, feed_dict={x: data[:batch_size, :]})\n",
    "    decoded = vae(data[:batch_size, :])\n",
    "    for i in range(10):\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               :digit_size] = tf.reshape(data[i, :],(digit_size, digit_size))\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               digit_size:] = tf.reshape(decoded[i, :],(digit_size, digit_size))\n",
    "    ax = fig.add_subplot(1, 2, fid_idx + 1)\n",
    "    ax.imshow(figure, cmap='Greys_r')\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "95lpEe2cOnMi"
   },
   "source": [
    "### Sending the results of your best model as Task 3 submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KudUfupuOnMi"
   },
   "outputs": [],
   "source": [
    "grader.submit_best_val_loss(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WEclzA3WOnMk"
   },
   "source": [
    "## Hallucinating new data\n",
    "**Task 4** Write code to generate new samples of images from your trained VAE. To do that you have to sample from the prior distribution $p(t)$ and then from the likelihood $p(x \\mid t)$.\n",
    "\n",
    "**Note** that the sampling you've written in Task 2 was for the variational distribution $q(t \\mid x)$, while here you need to sample from the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGLqzZD4OnMm"
   },
   "outputs": [],
   "source": [
    "n_samples = 10  # To pass automatic grading please use at least 2 samples here.\n",
    "# YOUR CODE HERE.\n",
    "# ...\n",
    "# sampled_im_mean is a tf.Tensor of size 10 x 784 with 10 random\n",
    "# images sampled from the vae model.\n",
    "sampled_im_mean = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Lzh_yW0OnMo"
   },
   "outputs": [],
   "source": [
    "sampled_im_mean_np = sess.run(sampled_im_mean)\n",
    "# Show the sampled images.\n",
    "plt.figure()\n",
    "for i in range(n_samples):\n",
    "    ax = plt.subplot(n_samples // 5 + 1, 5, i + 1)\n",
    "    plt.imshow(sampled_im_mean_np[i, :].reshape(28, 28), cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bqdpVNUOnMq"
   },
   "outputs": [],
   "source": [
    "grader.submit_hallucinating(sess, sampled_im_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMuhWEYBOnMt"
   },
   "source": [
    "# Conditional VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ly1YYFktOnMu"
   },
   "source": [
    "In the final task, you will modify your code to obtain Conditional Variational Autoencoder [1]. The idea is very simple: to be able to control the samples you generate, we condition all the distributions on some additional information. In our case, this additional information will be the class label (the digit on the image, from 0 to 9).\n",
    "\n",
    "![](https://github.com/hse-aml/bayesian-methods-for-ml/blob/master/week5/CVAE.png?raw=1)\n",
    "\n",
    "So now both the likelihood and the variational distributions are conditioned on the class label: $p(x \\mid t, \\text{label}, w)$, $q(t \\mid x, \\text{label}, \\phi)$.\n",
    "\n",
    "The only thing you have to change in your code is to concatenate input image $x$ with (one-hot) label of this image to pass into the encoder $q$ and to concatenate latent code $t$ with the same label to pass into the decoder $p$. Note that it's slightly harder to do with convolutional encoder/decoder model.\n",
    "\n",
    "[1] Sohn, Kihyuk, Honglak Lee, and Xinchen Yan. “Learning Structured Output Representation using Deep Conditional Generative Models.” Advances in Neural Information Processing Systems. 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6nvfNt0OnMv"
   },
   "source": [
    "## Final task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tbk2ICH-OnMw"
   },
   "source": [
    "**Task 5.1** Implement CVAE model. You may reuse ```create_encoder``` and ```create_decoder``` modules defined previously (now you can see why they accept the input size as an argument ;) ). You may also need `concatenate` Keras layer to concatenate labels with input data and latent code.\n",
    "\n",
    "To finish this task, you should go to `Conditionally hallucinate data` section and find there Task 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxgJjuAhOnMw"
   },
   "outputs": [],
   "source": [
    "# One-hot labels placeholder.\n",
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "label = Input(batch_shape=(batch_size, 10))\n",
    "\n",
    "# YOUR CODE HERE.\n",
    "cond_t_mean =  # Mean of the latent code (without label) for cvae model.\n",
    "cond_t_log_var = # Logarithm of the variance of the latent code (without label) for cvae model.\n",
    "cond_x_decoded_mean =  # Final output of the cvae model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I49rDcnrOnMy"
   },
   "source": [
    "## Define the loss and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1NvnF9yOnMz"
   },
   "outputs": [],
   "source": [
    "conditional_loss = vlb_binomial(x, cond_x_decoded_mean, cond_t_mean, cond_t_log_var)\n",
    "cvae = Model([x, label], cond_x_decoded_mean)\n",
    "cvae.compile(optimizer=keras.optimizers.RMSprop(lr=0.001), loss=lambda x, y: conditional_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9Jy93oNOnM0"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hz9X7fVNOnM0"
   },
   "outputs": [],
   "source": [
    "hist = cvae.fit(x=[x_train, y_train],\n",
    "                y=x_train,\n",
    "                shuffle=True,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=([x_test, y_test], x_test),\n",
    "                verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vweB4rkDOnM5"
   },
   "source": [
    "### Visualize reconstructions for train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c2KreOnWOnM6"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "for fid_idx, (x_data, y_data, title) in enumerate(\n",
    "            zip([x_train, x_test], [y_train, y_test], ['Train', 'Validation'])):\n",
    "    n = 10  # figure with 10 x 2 digits\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * 2))\n",
    "    decoded = sess.run(cond_x_decoded_mean,\n",
    "                       feed_dict={x: x_data[:batch_size, :],\n",
    "                                  label: y_data[:batch_size, :]})\n",
    "    for i in range(10):\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               :digit_size] = x_data[i, :].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               digit_size:] = decoded[i, :].reshape(digit_size, digit_size)\n",
    "    ax = fig.add_subplot(1, 2, fid_idx + 1)\n",
    "    ax.imshow(figure, cmap='Greys_r')\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qYZ0_FiQOnM8"
   },
   "source": [
    "## Conditionally hallucinate data\n",
    "**Task 5.2** Implement the conditional sampling from the distribution $p(x \\mid t, \\text{label})$ by firstly sampling from the prior $p(t)$ and then sampling from the likelihood $p(x \\mid t, \\text{label})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5f6pIbveOnM-"
   },
   "outputs": [],
   "source": [
    "# Prepare one hot labels of form\n",
    "#   0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 ...\n",
    "# to sample five zeros, five ones, etc\n",
    "curr_labels = np.eye(10)\n",
    "curr_labels = np.repeat(curr_labels, 5, axis=0)  # Its shape is 50 x 10.\n",
    "# YOUR CODE HERE.\n",
    "# ...\n",
    "# cond_sampled_im_mean is a tf.Tensor of size 50 x 784 with 5 random zeros,\n",
    "# then 5 random ones, etc sampled from the cvae model.\n",
    "cond_sampled_im_mean = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9DKAL2xOnNA"
   },
   "outputs": [],
   "source": [
    "cond_sampled_im_mean_np = sess.run(cond_sampled_im_mean)\n",
    "# Show the sampled images.\n",
    "plt.figure(figsize=(10, 10))\n",
    "global_idx = 0\n",
    "for digit in range(10):\n",
    "    for _ in range(5):\n",
    "        ax = plt.subplot(10, 5, global_idx + 1)\n",
    "        plt.imshow(cond_sampled_im_mean_np[global_idx, :].reshape(28, 28), cmap='gray')\n",
    "        ax.axis('off')\n",
    "        global_idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyz9NleMOnNC"
   },
   "outputs": [],
   "source": [
    "# Submit Task 5 (both 5.1 and 5.2).\n",
    "grader.submit_conditional_hallucinating(sess, cond_sampled_im_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMoVsQogOnNF"
   },
   "source": [
    "# Authorization & Submission\n",
    "To submit assignment parts to Cousera platform, please, enter your e-mail and token into variables below. You can generate a token on this programming assignment's page. <b>Note:</b> The token expires 30 minutes after generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pz5iFHZoOnNG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You want to submit these numbers:\n",
      "Task 1 (vlb): 157.59497\n",
      "Task 2.1 (samples mean): -0.12312889\n",
      "Task 2.2 (samples var): 0.03824601\n",
      "Task 3 (best val loss): ----------\n",
      "Task 4.1 (hallucinating mean): ----------\n",
      "Task 4.2 (hallucinating var): ----------\n",
      "Task 5.1 (conditional hallucinating mean): ----------\n",
      "Task 5.2 (conditional hallucinating var): ----------\n"
     ]
    }
   ],
   "source": [
    "STUDENT_EMAIL = \"tao_amadeus_shen@126.com\" # EMAIL HERE\n",
    "STUDENT_TOKEN = \"PGdZntcoYnUlZKUs\" # TOKEN HERE\n",
    "grader.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPjLc1JpOnNL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0GPFxR6cOnNV"
   },
   "source": [
    "# Playtime (UNGRADED)\n",
    "Once you passed all the tests, modify the code above to work with the mixture of Gaussian distributions (in contrast to the mixture of Binomial distributions), and redo the experiments with CIFAR-10 dataset, which are full-color natural images with much more diverse structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-Gv4MoqOnNW"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YlMJkjGcOnNa"
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_train[7, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q98v82S7OnNd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Vae_assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
